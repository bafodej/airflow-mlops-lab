# Airflow MLOps Lab - Pipeline Machine Learning

üìã Description
Ce projet d√©montre l'industrialisation d'un pipeline ML avec Apache Airflow 3.1.0 pour automatiser le workflow complet d'un mod√®le de r√©gression logistique sur le dataset advertising.csv (pr√©diction de conversions TV/radio/newspaper). Le pipeline orchestre 7 t√¢ches critiques MLOps :‚Äã

load_data : Chargement dataset (Pandas, 200 samples).

preprocess_data : Nettoyage, scaling (MinMaxScaler), feature engineering.

separate_data : Split train/test (80/20, 160/40 samples).

build_model : Entra√Ænement LogisticRegression (scikit-learn).

evaluate_model : √âvaluation accuracy (XCom storage, typiquement 0.85+).

success_notification : Email SMTP (Gmail, alertes production).

call_api : Int√©gration Flask API (POST status sur port 5000, 200 OK confirm√©).

Objectifs p√©dagogiques (bas√© sur √©nonc√© Simplon Lille) :

Automatisation workflow ML (pas conception mod√®le).

Orchestration DAGs, monitoring, notifications, et int√©grations externes.

MLOps production-ready : Tra√ßabilit√© XCom, retries, health checks API v2.

Valeur MLOps : Pipeline reproductible, scalable (16 runs max), avec monitoring REST v2 et email alerts. Id√©al pour formation D√©veloppeur IA/Data Analyse.‚Äã

üõ†Ô∏è Stack Technique
Composant	Version	R√¥le
Apache Airflow	3.1.0	Orchestration DAGs, scheduling (@daily), monitoring UI/API v2. ‚Äã
Docker & Docker Compose	20.x	Conteneurisation (webserver, scheduler, worker, postgres, flask). ‚Äã
Python	3.12.12	Scripts ML (scikit-learn, pandas), DAGs PythonOperator/BashOperator.
Scikit-learn	1.3+	Mod√®le LogisticRegression, preprocessing (train/test split, accuracy).
Flask	3.1.3	API supervision (port 5000, endpoints /api/v1/update-status, /api/v1/status).
PostgreSQL	16	M√©tadonn√©es (DAG runs, task instances, XCom accuracy), volumes persistants.
SMTP Provider	apache-airflow-providers-smtp	Notifications email (Gmail config). ‚Äã
D√©pendances : pandas, numpy, joblib (sauvegarde mod√®le .pkl), requests (call_api).

Projet : Lab MLOps - Industrialisation pipeline ML avec Airflow.

 Installation & D√©marrage
Pr√©requis
Docker : docker --version (20.x+ requis).

Docker Compose : docker compose version (v2+).

Git : Clone repo : git clone <ton-repo> && cd airflow-mlops-lab.

Python : 3.12 (pour dev local, optionnel).

Variables d'environnement : Cr√©e .env avec SMTP Gmail (email/password/app-password).‚Äã

Fichier .env exemple (non commit√©) :



bash
git clone <repo> && cd airflow-mlops-lab
cp .env.example .env  # √âdite avec tes credentials Gmail
Build & D√©marrage Docker :

bash
docker compose up -d  # D√©marre 7 services (webserver:8080, postgres:5432, flask:5000)
docker compose ps     # V√©rifie : tous "Up" (healthy)
Initialisation Airflow (premi√®re fois) :

bash
docker compose exec airflow-worker airflow db init  # Cr√©e tables PostgreSQL
docker compose exec airflow-worker airflow db upgrade  # Migrations 3.1.0
docker compose exec airflow-worker airflow users create \
  --username admin --firstname Admin --lastname User --role Admin \
  --email admin@example.com --password admin  # User admin/admin
Acc√®s :


API v2 Health : curl http://localhost:8080/api/v2/monitor/health (tous "healthy").‚Äã

Flask API : curl http://localhost:5000/api/v1/status ({} ou status pipeline).

Swagger : Pas support√© en 3.1.0 (utilise API v2 endpoints directs).‚Äã

V√©rification Pipeline :

UI : Active ml_pipeline_lab, trigger manual.

Logs : docker logs airflow-worker --tail 20 | grep "ml_pipeline_lab" (success 7/7 t√¢ches).

Mod√®le : /opt/airflow/dags/ml_pipeline/model/logistic_regression_model.pkl (sauvegard√©).

Temps estim√© : 5-10 min (premi√®re fois), 1 min (red√©marrage).

üìñ Utilisation
Ex√©cution Pipeline ML
UI Airflow (recommand√©) :

Navigue : localhost:8080 ‚Üí DAGs ‚Üí ml_pipeline_lab.

Toggle "On", clique "Trigger DAG" (manual).

Graph View : Visualise 7 t√¢ches (load_data ‚Üí call_api).

Grid : Monitor status (toutes vertes apr√®s 634s).‚Äã

CLI Airflow :

bash
docker compose exec airflow-worker airflow dags list  # Liste DAGs (ml_pipeline_lab)
docker compose exec airflow-worker airflow dags trigger ml_pipeline_lab  # Trigger
docker compose exec airflow-worker airflow dags state ml_pipeline_lab manual__$(date +%Y-%m-%dT%H:%M:%S)  # Status
Monitoring :

XCom Metrics : UI ‚Üí evaluate_model ‚Üí XCom (accuracy ~0.85).

Logs T√¢ches : UI ‚Üí call_api ‚Üí Logs (recherche "API Flask appel√©e : 200").

Email : V√©rifie inbox Gmail (notification success).

API Flask : docker logs flask-api --tail 10 (POST re√ßu de call_api).

Planification :

Schedule : @daily (0 0 * * *).

Backfill : airflow dags backfill ml_pipeline_lab --start-date 2025-10-01.‚Äã

Exemple Sortie Pipeline
Dataset : 200 rows (TV, radio, newspaper ‚Üí conversion 0/1).

Mod√®le : LogisticRegression, accuracy stock√©e XCom.

Artefacts : model/logistic_regression_model.pkl (joblib), data/preprocessed_advertising.csv.

Int√©gration : POST vers Flask API : {"dag_id": "ml_pipeline_lab", "status": "success"} (200 OK).

üèóÔ∏è Structure du Projet
text
airflow-mlops-lab/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ ml_airflow_lab.py          # DAG principal (7 t√¢ches PythonOperator/BashOperator)
‚îÇ   ‚îî‚îÄ‚îÄ model_development.py       # Mod√®le ML source (LogisticRegression)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ advertising.csv            # Dataset input (200 samples)
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îî‚îÄ‚îÄ logistic_regression_model.pkl  # Mod√®le entra√Æn√© (output)
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                     # Flask API (endpoints /api/v1/*)
‚îú‚îÄ‚îÄ docker-compose.yaml            # Services (airflow, postgres, flask)
‚îú‚îÄ‚îÄ .env.example                   # Config SMTP, DB (non commit√©)
‚îú‚îÄ‚îÄ requirements.txt               # D√©pendances Python (scikit-learn, etc.)
‚îî‚îÄ‚îÄ README.md                      # Ce fichier
Volumes Docker (persistants) :

./dags:/opt/airflow/dags (code DAGs).

./logs:/opt/airflow/logs (logs t√¢ches).

postgres_db_volume:/var/lib/postgresql/data (m√©tadonn√©es XCom).

üîß Commandes Utilitaires (Cheatsheet Int√©gr√©)
Lancement & Services Airflow
Commande	Description	V√©rification
docker compose up -d	D√©marre tout (, scheduler, flask:5000). ‚Äã	docker ps (7 conteneurs Up).
docker compose down	Arr√™te services (garde volumes).	docker compose ps (0 actifs).
airflow webserver --port 8080	Lance UI (standalone, non-Docker). ‚Äã	http://localhost:8080 (dashboard).
airflow scheduler	Lance orchestration DAGs.	ps aux | grep scheduler (PID > 0).
airflow db init	Initialise DB PostgreSQL.	airflow db check (healthy).
Logs & Monitoring
Commande	Description	Exemple Sortie
docker logs -f airflow-worker-1	Logs worker temps r√©el (t√¢ches ML). ‚Äã	"Starting load_data task", "Accuracy: 0.85".
docker logs --tail 100 airflow-scheduler-1	Derniers logs scheduler (ex√©cutions).	"DAG ml_pipeline_lab triggered".
docker logs -f flask-api-1	Logs API Flask (POST call_api).	POST /api/v1/update-status 200.
curl http://localhost:8080/api/v2/monitor/health	Health API v2 (tous healthy). ‚Äã	{"metadatabase":"healthy", "scheduler":"healthy"}.
docker compose restart airflow-scheduler	Relance scheduler (apr√®s edit DAG).	docker logs scheduler --tail 10 (red√©marr√©).
Nginx (Proxy Optionnel)
Commande	Description	V√©rification
sudo nginx -s reload	Recharge config reverse proxy. ‚Äã	ps aux | grep nginx (PID actif).
sudo nginx -t	Test config nginx.	nginx: configuration ok.
sudo systemctl status nginx	Statut service (systemd).	nginx.service: active (running).
Gestion Utilisateurs & DB
User Admin : admin / admin (ou tes creds : "admin": "geXFHK5pRahNywfE").‚Äã

DB Shell : docker compose exec postgres psql -U airflow -d airflow (\dt xcom pour metrics).

Nettoyage : docker volume prune (volumes orphelins), docker system prune -f (images inutiles).

Debugging Pipeline
DAG Status : UI ‚Üí Grid (toutes t√¢ches success/vertes).

XCom Inspect : UI ‚Üí evaluate_model ‚Üí XCom (cl√© accuracy, valeur float).

Email Test : docker compose exec airflow-worker airflow tasks test ml_pipeline_lab success_notification 2025-10-26.

API Test : curl -X POST http://localhost:5000/api/v1/update-status -d '{"status":"success"}' -H "Content-Type: application/json".


Logs G√©n√©raux : docker compose logs -f (tous services temps r√©el).
Erreurs Courantes : V√©rifie docker-compose.yaml (ports, env vars), airflow.cfg (providers smtp install√©s).


üë§ Auteur
Bafode Jaiteh
